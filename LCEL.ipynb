{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language(LCEL)\n",
    "다양한 구성 요소를 단일 체인으로 결합  \n",
    "https://wikidocs.net/233344\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "영어 대화 예시:\n",
      "\n",
      "English Conversation:\n",
      "I would like to order some food at the restaurant, please.\n",
      "Can I have a menu?\n",
      "Sure, here you go. Please take your time and look through it. If you need any help or recommendations, just let me know.\n",
      "Thank you very much! I'll take a moment to decide what I want.\n",
      "Great, we appreciate your business. Let us know when you're ready to place your order.\n",
      "I think I found something that looks good. Can I have the [specific dish] please?\n",
      "Sure thing! Would you like anything else with it or any side dishes?\n",
      "No thank you, just the main dish is fine for now.\n",
      "Alright then, we will get right on that and bring it out to your table shortly. Enjoy your meal!\n",
      "영어 대화 예시:\n",
      "\n",
      "English Conversation:\n",
      "I would like to order some food at the restaurant, please.\n",
      "Can I have a menu?\n",
      "Sure, here you go. Please take your time and look through it. If you need any help or recommendations, just let me know.\n",
      "Thank you very much! I'll take a moment to decide what I want.\n",
      "Great, we appreciate your business. Let us know when you're ready to place your order.\n",
      "I think I found something that looks good. Can I have the [specific dish] please?\n",
      "Sure thing! Would you like anything else with it or any side dishes?\n",
      "No thank you, just the main dish is fine for now.\n",
      "Alright then, we will get right on that and bring it out to your table shortly. Enjoy your meal!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "\n",
    "# 2\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 3\n",
    "template = \"\"\"\n",
    "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
    "답변은 항상 한글로 작성해 주세요.\n",
    "\n",
    "질문:\n",
    "{question}에 대하여 설명해 주세요.\n",
    "\n",
    "FORMAT:\n",
    "- 개요:\n",
    "- 예시:\n",
    "- 출처:\n",
    "\"\"\"\n",
    "\n",
    "# 4\n",
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "##########\n",
    "# llm 모델\n",
    "##########\n",
    "local_path = (\n",
    "    \"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\"\n",
    ")\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    backend=\"mps\", # GPU 설정\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSONPatch 청크 스트리밍\n",
    "\n",
    "https://wikidocs.net/233345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta. Creating a new one with MEAN pooling.\n",
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '65842086-4c8f-4148-9f4c-0d58101b8f59',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'ecfbd609-acec-4293-80ea-609f46f99ad9',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2024-05-14T13:39:57.127+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:context', 'FAISS', 'HuggingFaceBgeEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='원영이가 살고 있는 곳은 대한민국 입니다.')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2024-05-14T13:39:57.248+00:00'})\n",
      "\n",
      "A. 미국\n",
      "B. 중국\n",
      "C. 일본\n",
      "D. 대한민국\n",
      "\n",
      "정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. 따라서 정답은 D 옵션인 '대한민국'입니다.----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': '\\n'\n",
      "           'A. 미국\\n'\n",
      "           'B. 중국\\n'\n",
      "           'C. 일본\\n'\n",
      "           'D. 대한민국\\n'\n",
      "           '\\n'\n",
      "           '정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. '\n",
      "           \"따라서 정답은 D 옵션인 '대한민국'입니다.\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': '\\n'\n",
      "           'A. 미국\\n'\n",
      "           'B. 중국\\n'\n",
      "           'C. 일본\\n'\n",
      "           'D. 대한민국\\n'\n",
      "           '\\n'\n",
      "           '정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. '\n",
      "           \"따라서 정답은 D 옵션인 '대한민국'입니다.\"})\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "##########\n",
    "# llm 모델\n",
    "##########\n",
    "local_path = (\n",
    "    \"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\"\n",
    ")\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    backend=\"mps\", # GPU 설정\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "#################\n",
    "# embedding model\n",
    "#################\n",
    "model_name = 'BM-K/KoSimCSE-roberta'\n",
    "model_kwargs = {'device': 'mps'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "###################################\n",
    "#  FAISS 벡터 스토어를 이용해 텍스트를 인덱싱\n",
    "###################################\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"원영이가 살고 있는 곳은 대한민국 입니다.\"], embedding=embeddings_model\n",
    ")\n",
    "#########################################################################\n",
    "# retriever와 RunnablePassthrough를 통해 질문의 컨텍스트를 검색하고, 질문을 그대로 전달\n",
    "# retrieval_chain은 이러한 컴포넌트들을 파이프라인으로 연결하고, StrOutputParser를 사용하여 모델의 출력을 문자열로 파싱합니다.\n",
    "#########################################################################\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# astream_log: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다\n",
    "async for chunk in retrieval_chain.astream_log(\n",
    "    \"원영이가 살고 있는 곳은 어딘가요?\", include_names=[\"Docs\"]\n",
    "):\n",
    "    print(\"-\" * 40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stream`: 응답의 청크를 스트리밍합니다  \n",
    "`invoke`: 입력에 대해 체인을 호출합니다  \n",
    "`batch`: 입력 목록에 대해 체인을 호출합니다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"ChatGPT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
    "\n",
    "chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.\n",
      "멀티모달은 여러 모드를 통해 정보를 전달하는 것을 말합니다. 이는 시각, 청각 또는 촉각을 포함할 수 있습니다. 예를 들어, 비디오는 시청자에게 동시에 이미지(시각)와 소리(청각)를 제공합니다. 마찬가지로, 만져볼 수 있는 물건들은 촉감을 통한 정보 제공에 도움을 줍니다. 멀티모달은 사람들이 정보를 더 잘 이해하고 기억하는데 도움이 될 수 있으며, 다양한 감각 채널을 통해 전달되기 때문입니다.\n",
      "프로그래밍은 복잡한 작업을 수행하기 위해 기계를 지시하는 일련의 명령어들을 작성하는 과정입니다. 이러한 명령어들은 특정 언어, 예를 들어 C++ 또는 Python을 사용하여 작성됩니다. 이 과정은 문제 해결 능력 및 논리적 사고 능력을 향상시키는 데 도움이 됩니다.\n",
      "\n",
      "1. \"머신러닝은 기계가 데이터로부터 학습하고, 패턴을 인식하고, 예측을 할 수 있게 하는 인공지능의 한 분야입니다.\"\n",
      "2. \"기계들은 인간의 개입 없이도 새로운 정보를 지속적으로 수집함으로써 지능적으로 적응할 수 있습니다.\"\n",
      "3. \"머신러닝 알고리즘과 기술은 다양한 산업 분야에서 의사결정 과정을 개선하고 효율성을 높이는 데 사용되고 있습니다.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.',\n",
       " '\\n멀티모달은 여러 모드를 통해 정보를 전달하는 것을 말합니다. 이는 시각, 청각 또는 촉각을 포함할 수 있습니다. 예를 들어, 비디오는 시청자에게 동시에 이미지(시각)와 소리(청각)를 제공합니다. 마찬가지로, 만져볼 수 있는 물건들은 촉감을 통한 정보 제공에 도움을 줍니다. 멀티모달은 사람들이 정보를 더 잘 이해하고 기억하는데 도움이 될 수 있으며, 다양한 감각 채널을 통해 전달되기 때문입니다.',\n",
       " '\\n프로그래밍은 복잡한 작업을 수행하기 위해 기계를 지시하는 일련의 명령어들을 작성하는 과정입니다. 이러한 명령어들은 특정 언어, 예를 들어 C++ 또는 Python을 사용하여 작성됩니다. 이 과정은 문제 해결 능력 및 논리적 사고 능력을 향상시키는 데 도움이 됩니다.',\n",
       " '\\n\\n1. \"머신러닝은 기계가 데이터로부터 학습하고, 패턴을 인식하고, 예측을 할 수 있게 하는 인공지능의 한 분야입니다.\"\\n2. \"기계들은 인간의 개입 없이도 새로운 정보를 지속적으로 수집함으로써 지능적으로 적응할 수 있습니다.\"\\n3. \"머신러닝 알고리즘과 기술은 다양한 산업 분야에서 의사결정 과정을 개선하고 효율성을 높이는 데 사용되고 있습니다.\"']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최대 3개의 작업을 동시에 처리\n",
    "\n",
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`astream`: 비동기적으로 응답의 청크를 스트리밍합니다  \n",
    "`ainvoke`: 비동기적으로 입력에 대해 체인을 호출합니다  \n",
    "`abatch`: 비동기적으로 입력 목록에 대해 체인을 호출합니다  \n",
    "`astream_log`: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYouTube\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\u001b[39;00m\n",
      "\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s\u001b[38;5;241m.\u001b[39mcontent, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
    "async for s in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain 객체의 ainvoke 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. NonVisual Desktop Access, 즉 NVDA는 시각 장애가 있는 개인들이 화면 내용을 읽고 이해할 수 있도록 도와주는 무료 소프트웨어 응용 프로그램입니다.\n",
      "2. 이 접근성 도구로 사용자들은 키보드 단축키와 음성 합성을 통해 웹사이트, 문서 및 기타 디지털 콘텐츠를 효과적으로 상호 작용할 수 있습니다.\n",
      "3. NVDA는 다양한 운영 체제에서 사용할 수 있으며 지속적으로 업데이트되고 개선되어 시각 장애가 있는 개인들이 정보에 접근하고 기술을 활용할 수 있도록 보장합니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. NonVisual Desktop Access, 즉 NVDA는 시각 장애가 있는 개인들이 화면 내용을 읽고 이해할 수 있도록 도와주는 무료 소프트웨어 응용 프로그램입니다.\\n2. 이 접근성 도구로 사용자들은 키보드 단축키와 음성 합성을 통해 웹사이트, 문서 및 기타 디지털 콘텐츠를 효과적으로 상호 작용할 수 있습니다.\\n3. NVDA는 다양한 운영 체제에서 사용할 수 있으며 지속적으로 업데이트되고 개선되어 시각 장애가 있는 개인들이 정보에 접근하고 기술을 활용할 수 있도록 보장합니다.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\n",
    "await chain.ainvoke({\"topic\": \"NVDA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.\n",
      "Facebook은 전 세계 수백만 명의 사람들이 친구, 가족 및 관심사와 연결될 수 있는 소셜 네트워킹 플랫폼입니다. 사용자들은 자신의 프로필을 만들고 업데이트를 게시하며 다른 사람들과 상호 작용할 수 있습니다. 또한 페이스북 메신저와 인스타그램과 같은 다양한 기능을 제공하여 사용자가 서로 소통하고 콘텐츠를 공유할 수 있게 합니다.\n",
      "\n",
      "Facebook은 2004년 하버드 대학교 학생인 마크 주커버그에 의해 창립되었습니다. 처음에는 학교 내의 학생들만을 대상으로 했지만, 이후 전 세계 수백만 명의 사용자를 보유한 글로벌 플랫폼으로 성장했습니다. Facebook은 사용자 데이터를 수집하고 이를 기반으로 타겟 광고를 제공하는 것으로 알려져 있으며, 이는 회사의 주요 수익원입니다.\n",
      "\n",
      "Facebook은 개인정보 보호 문제와 잘못된 정보 확산에 대한 비판을 받아왔으며, 이로 인해 많은 논란이 일고 있습니다. 그럼에도 불구하고 전 세계적으로 가장 인기 있는 소셜 미디어 플랫폼 중 하나로 남아있으며, 사람들이 연결되고 정보를 공유하는 데 있어 중요한 역할을 하고 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nYouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.',\n",
       " '\\nFacebook은 전 세계 수백만 명의 사람들이 친구, 가족 및 관심사와 연결될 수 있는 소셜 네트워킹 플랫폼입니다. 사용자들은 자신의 프로필을 만들고 업데이트를 게시하며 다른 사람들과 상호 작용할 수 있습니다. 또한 페이스북 메신저와 인스타그램과 같은 다양한 기능을 제공하여 사용자가 서로 소통하고 콘텐츠를 공유할 수 있게 합니다.\\n\\nFacebook은 2004년 하버드 대학교 학생인 마크 주커버그에 의해 창립되었습니다. 처음에는 학교 내의 학생들만을 대상으로 했지만, 이후 전 세계 수백만 명의 사용자를 보유한 글로벌 플랫폼으로 성장했습니다. Facebook은 사용자 데이터를 수집하고 이를 기반으로 타겟 광고를 제공하는 것으로 알려져 있으며, 이는 회사의 주요 수익원입니다.\\n\\nFacebook은 개인정보 보호 문제와 잘못된 정보 확산에 대한 비판을 받아왔으며, 이로 인해 많은 논란이 일고 있습니다. 그럼에도 불구하고 전 세계적으로 가장 인기 있는 소셜 미디어 플랫폼 중 하나로 남아있으며, 사람들이 연결되고 정보를 공유하는 데 있어 중요한 역할을 하고 있습니다.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\n",
    "await chain.abatch(\n",
    "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from llama_cpp import Llama 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 435 tensors from ./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = 01-original_model\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 48\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 40960\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,40960]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,40960]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,40960]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q5_K:  289 tensors\n",
      "llama_model_loader: - type q6_K:   49 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 261/40960 vs 260/40960 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 40960\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 34B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 10.80 B\n",
      "llm_load_print_meta: model size       = 7.13 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = 01-original_model\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32000 '<|im_end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/49 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  7298.02 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    96.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   96.00 MiB, K (f16):   48.00 MiB, V (f16):   48.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.16 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    88.00 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1542\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'You are a helpful assistant.' %}{% endif %}{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 %}{{'<|im_start|>system\\n' + system_message + '<|im_end|>\\n'}}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.vocab_size': '40960', 'llama.attention.head_count_kv': '8', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'general.file_type': '17', 'llama.feed_forward_length': '14336', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '10000.000000', 'llama.embedding_length': '4096', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': '01-original_model', 'llama.block_count': '48'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'You are a helpful assistant.' %}{% endif %}{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 %}{{'<|im_start|>system\n",
      "' + system_message + '<|im_end|>\n",
      "'}}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <s>\n",
      "\n",
      "llama_print_timings:        load time =    5263.19 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    62 runs   (    0.12 ms per token,  8497.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5263.14 ms /    27 tokens (  194.93 ms per token,     5.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8191.03 ms /    61 runs   (  134.28 ms per token,     7.45 tokens per second)\n",
      "llama_print_timings:       total time =   13572.54 ms /    88 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-5b858b5e-4261-47f0-99ea-26ac2e72f214', 'object': 'chat.completion', 'created': 1715677476, 'model': './EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '대한민국의 수도는 서울입니다. 서울은 나라의 정치, 경제, 문화 중심지로서 중요한 역할을 하고 있습니다. 약 1000만 명이 거주하는 대도시로, 다양한 역사 유적지와 현대적인 건축물들이 어우러져 있어 방문객들에게 풍부한 경험을 제공합니다.'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 27, 'completion_tokens': 61, 'total_tokens': 88}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(model_path=\"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\")\n",
    "\n",
    "question = \"대한민국의 수도는?\"\n",
    "\n",
    "result = llm.create_chat_completion(\n",
    "        \n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "    }],\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다. 서울은 나라의 정치, 경제, 문화 중심지로서 중요한 역할을 하고 있습니다. 약 1000만 명이 거주하는 대도시로, 다양한 역사 유적지와 현대적인 건축물들이 어우러져 있어 방문객들에게 풍부한 경험을 제공합니다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from langchain_community.llms import GPT4All 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = \"{country}의 수도는 뭐야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ITWorld Korea\n",
      "스마트폰이 얼마나 되는지 알고 싶으세요? 이 질문에 대한 답은 여러 가지가 있습니다. 하지만, 가장 정확한 대답을 원한다면 IDC(International Data Corporation)를 참고하세요.\n",
      "IDC에 따르면 전 세계적으로 약 10억 대의 스마트폰을 사용 중이라고 합니다. 이는 지난해 같은 기간보다 무려 42% 증가한 수치입니다. 이 수치는 올해 말까지 35% 더 성장할 것으로 예상됩니다. IDC는 연말까지 총 13억 6,800만대의 기기가 판매될 것이라고 예측하고 있습니다.\n",
      "IDC의 모바일 폰 부문 책임자인 라몬 로페즈(Ramon Lopez)에 따르면 \"스마트폰은 이제 소비자 시장에서 가장 빠르게 성장하는 카테고리 중 하나가 되었습니다.\"라고 합니다. 그는 또한 스마트폰을 사용하는 사람들의 수가 2015년까지 전 세계적으로 약 3억 명으로 증가할 것으로 예상하고 있습니다.\n",
      "이 수치는 IDC가 지난달에 발표한 자료와 일치합니다. 당시에는 올해 말까지 총 9억 대의 기기가 판매될 것이라고 예측했었습니다. 하지만, 로페즈는"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "local_path = (\n",
    "    \"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\"\n",
    ")\n",
    "\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    # backend=\"gpu\", # GPU 설정\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "#####################################\n",
    "# LCEL(LangChain Expression Language)\n",
    "# prompt 템플릿과 모델을 함께 연결\n",
    "#####################################\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 질의 실행\n",
    "response = chain.invoke({\"country\": \"Smart phone\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "개요:\n",
      "식당에 가기 위해서는 먼저 식당을 선택해야 합니다. 그 다음에는 메뉴를 살펴보고 주문을 할 수 있는 테이블이나 카운터로 이동합니다. 원하는 음식을 선택한 후, 종업원에게 주문하고 싶은 음식과 음료의 종류를 알려줍니다. 그들은 당신의 주문을 받아서 준비하며, 식사를 즐길 준비를 하면서 기다립니다.\n",
      "\n",
      "예시:\n",
      "식당에 가기 위해서는 먼저 식당을 선택해야 합니다. 예를 들어 '맛있는 식당'이라고 해봅시다. 그 다음에는 메뉴를 살펴보고 주문을 할 수 있는 테이블이나 카운터로 이동합니다. 맛있는 치즈버거와 콜라를 먹고 싶다고 결정했습니다. 종업원에게 다가가서 \"치즈버거 하나랑 콜라도 주세요.\"라고 말씀드립니다. 그들은 당신의 주문을 받아서 준비하며, 식사를 즐길 준비를 하면서 기다립니다.\n",
      "\n",
      "출처:\n",
      "이 정보는 식당에서의 일반적인 식사 경험을 바탕으로 합니다.\n",
      "개요:\n",
      "식당에 가기 위해서는 먼저 식당을 선택해야 합니다. 그 다음에는 메뉴를 살펴보고 주문을 할 수 있는 테이블이나 카운터로 이동합니다. 원하는 음식을 선택한 후, 종업원에게 주문하고 싶은 음식과 음료의 종류를 알려줍니다. 그들은 당신의 주문을 받아서 준비하며, 식사를 즐길 준비를 하면서 기다립니다.\n",
      "\n",
      "예시:\n",
      "식당에 가기 위해서는 먼저 식당을 선택해야 합니다. 예를 들어 '맛있는 식당'이라고 해봅시다. 그 다음에는 메뉴를 살펴보고 주문을 할 수 있는 테이블이나 카운터로 이동합니다. 맛있는 치즈버거와 콜라를 먹고 싶다고 결정했습니다. 종업원에게 다가가서 \"치즈버거 하나랑 콜라도 주세요.\"라고 말씀드립니다. 그들은 당신의 주문을 받아서 준비하며, 식사를 즐길 준비를 하면서 기다립니다.\n",
      "\n",
      "출처:\n",
      "이 정보는 식당에서의 일반적인 식사 경험을 바탕으로 합니다.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
    "답변은 항상 한글로 작성해 주세요.\n",
    "\n",
    "질문:\n",
    "{question}에 대하여 설명해 주세요.\n",
    "\n",
    "FORMAT:\n",
    "- 개요:\n",
    "- 예시:\n",
    "- 출처:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "영어 대화:\n",
      "\"Excuse me, sir/ma'am, I would like to place an order.\"\n",
      "\n",
      "번역:\n",
      "저에게 잠시 시간을 내어주실 수 있을까요? 주문을 하고 싶습니다.\n",
      "영어 대화:\n",
      "\"Excuse me, sir/ma'am, I would like to place an order.\"\n",
      "\n",
      "번역:\n",
      "저에게 잠시 시간을 내어주실 수 있을까요? 주문을 하고 싶습니다.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='\\n당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\\n\\n상황:\\n{question}\\n\\nFORMAT:\\n- 영어 회화:\\n- 한글 해석:\\n')\n",
       "| GPT4All(verbose=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x16a13a290>], model='./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf', streaming=True, client=<gpt4all.gpt4all.GPT4All object at 0x16a139ed0>)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dir(chain)[78:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "영어 대화:\n",
      "John: 안녕하세요, Pizza Hut에 전화드렸습니다. 한 판의 슈퍼 사워 치즈 페페로니 피자를 주세요. 그리고 사이드로 감자튀김도 같이 보내주세요. 감사합니다!\n",
      "\n",
      "번역: 존은 피자헛에 전화를 걸어 슈퍼 소어 체이스 페페로니 피자와 함께 감자튀김을 주문했습니다. 그는 주문을 마치고 '감사합니다'라고 말했습니다.\n",
      "영어 대화:\n",
      "John: 안녕하세요, Pizza Hut에 전화드렸습니다. 한 판의 슈퍼 사워 치즈 페페로니 피자를 주세요. 그리고 사이드로 감자튀김도 같이 보내주세요. 감사합니다!\n",
      "\n",
      "번역: 존은 피자헛에 전화를 걸어 슈퍼 소어 체이스 페페로니 피자와 함께 감자튀김을 주문했습니다. 그는 주문을 마치고 '감사합니다'라고 말했습니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"미국에서 피자 주문\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "양자 역학은 원자의 행동을 지배하는 물리학의 한 분야입니다. 이 작은 입자들은 우리가 일상 생활에서 보는 세계와는 매우 다르게 작동합니다. 예를 들어, 그들은 동시에 여러 곳에 존재할 수 있으며(슈퍼포지션), 그들의 위치와 운동량을 정확히 측정할 수는 없습니다(불확정성 원칙).\n",
      "양자 역학을 이해하는 것은 도전적일 수 있지만, 그 원리를 탐구하는 것이 흥미롭습니다. 이 분야는 물리학에서 가장 활발한 분야 중 하나이며 새로운 발견이 지속적으로 이루어지고 있습니다. 양자 역학은 또한 현대 기술 발전에 필수적인 역할을 했으며, 예를 들어 트랜지스터와 레이저 등이 그것입니다.\n",
      "양자 역학의 기본 원리를 이해하기 위해 다음과 같은 몇 가지 핵심 개념을 살펴보겠습니다:\n",
      "* 입자의 파동-입자 이중성: 양자 세계에서 모든 것은 동시에 파동과 입자로 존재합니다. 이 개념은 아인슈타인의 광전 효과에 대한 설명에서 처음 소개되었습니다. 그는 빛이 전자기파의 형태로 방출되지만, 특정 조건 하에서는 개별 입자인 광자로 행동한다고 제안했습니다.\n",
      "* 슈퍼포지션: 양자 세계에서 입자들은 동시에 여러 곳에 존재할 수 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n양자 역학은 원자의 행동을 지배하는 물리학의 한 분야입니다. 이 작은 입자들은 우리가 일상 생활에서 보는 세계와는 매우 다르게 작동합니다. 예를 들어, 그들은 동시에 여러 곳에 존재할 수 있으며(슈퍼포지션), 그들의 위치와 운동량을 정확히 측정할 수는 없습니다(불확정성 원칙).\\n양자 역학을 이해하는 것은 도전적일 수 있지만, 그 원리를 탐구하는 것이 흥미롭습니다. 이 분야는 물리학에서 가장 활발한 분야 중 하나이며 새로운 발견이 지속적으로 이루어지고 있습니다. 양자 역학은 또한 현대 기술 발전에 필수적인 역할을 했으며, 예를 들어 트랜지스터와 레이저 등이 그것입니다.\\n양자 역학의 기본 원리를 이해하기 위해 다음과 같은 몇 가지 핵심 개념을 살펴보겠습니다:\\n* 입자의 파동-입자 이중성: 양자 세계에서 모든 것은 동시에 파동과 입자로 존재합니다. 이 개념은 아인슈타인의 광전 효과에 대한 설명에서 처음 소개되었습니다. 그는 빛이 전자기파의 형태로 방출되지만, 특정 조건 하에서는 개별 입자인 광자로 행동한다고 제안했습니다.\\n* 슈퍼포지션: 양자 세계에서 입자들은 동시에 여러 곳에 존재할 수 있습니다.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "input = {\"topic\": \"양자역학\"}\n",
    "\n",
    "# prompt 객체의 invoke 메서드를 사용하여 input을 전달하고 대화형 프롬프트 값을 생성합니다.\n",
    "prompt.invoke(input)\n",
    "\n",
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "(prompt | llm).invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "양자 역학은 원자의 행동을 지배하는 물리학의 한 분야입니다. 이 작은 입자들은 우리가 일상 생활에서 보는 세계와는 매우 다르게 작동합니다. 예를 들어, 그들은 동시에 여러 곳에 존재할 수 있으며(슈퍼포지션), 그들의 위치와 운동량을 정확히 측정할 수는 없습니다(불확정성 원칙).\n",
      "양자 역학을 이해하는 것은 도전적일 수 있지만, 그 원리를 탐구하는 것이 흥미롭습니다. 이 분야는 물리학에서 가장 활발한 분야 중 하나이며 새로운 발견이 지속적으로 이루어지고 있습니다. 양자 역학은 또한 현대 기술 발전에 필수적인 역할을 했으며, 예를 들어 트랜지스터와 레이저 등이 그것입니다.\n",
      "양자 역학의 기본 원리를 이해하기 위해 다음과 같은 몇 가지 핵심 개념을 살펴보겠습니다:\n",
      "* 입자의 파동-입자 이중성: 양자 세계에서 모든 것은 동시에 파동과 입자로 존재합니다. 이 개념은 아인슈타인의 광전 효과에 대한 설명에서 처음 소개되었습니다. 그는 빛이 전자기파의 형태로 방출되지만, 특정 조건 하에서는 개별 입자인 광자로 행동한다고 제안했습니다.\n",
      "* 슈퍼포지션: 양자 세계에서 입자들은 동시에 여러 곳에 존재할 수 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n양자 역학은 원자의 행동을 지배하는 물리학의 한 분야입니다. 이 작은 입자들은 우리가 일상 생활에서 보는 세계와는 매우 다르게 작동합니다. 예를 들어, 그들은 동시에 여러 곳에 존재할 수 있으며(슈퍼포지션), 그들의 위치와 운동량을 정확히 측정할 수는 없습니다(불확정성 원칙).\\n양자 역학을 이해하는 것은 도전적일 수 있지만, 그 원리를 탐구하는 것이 흥미롭습니다. 이 분야는 물리학에서 가장 활발한 분야 중 하나이며 새로운 발견이 지속적으로 이루어지고 있습니다. 양자 역학은 또한 현대 기술 발전에 필수적인 역할을 했으며, 예를 들어 트랜지스터와 레이저 등이 그것입니다.\\n양자 역학의 기본 원리를 이해하기 위해 다음과 같은 몇 가지 핵심 개념을 살펴보겠습니다:\\n* 입자의 파동-입자 이중성: 양자 세계에서 모든 것은 동시에 파동과 입자로 존재합니다. 이 개념은 아인슈타인의 광전 효과에 대한 설명에서 처음 소개되었습니다. 그는 빛이 전자기파의 형태로 방출되지만, 특정 조건 하에서는 개별 입자인 광자로 행동한다고 제안했습니다.\\n* 슈퍼포지션: 양자 세계에서 입자들은 동시에 여러 곳에 존재할 수 있습니다.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_output 메서드를 사용하여 AI 모델이 생성한 메시지 문자열로 출력합니다.\n",
    "(prompt | llm | StrOutputParser()).invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='{topic} 에 대하여 3문장으로 설명해줘.'))]) last=GPT4All(verbose=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x16a13a290>], model='./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf', streaming=True, client=<gpt4all.gpt4all.GPT4All object at 0x16a139ed0>)\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'GPT4AllOutput', 'type': 'string'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "멀티모달은 여러 모드를 통해 정보를 전달하는 것을 말합니다. 이는 시각, 청각 또는 촉각을 포함할 수 있습니다. 예를 들어, 비디오는 시청자에게 동시에 이미지(시각)와 소리(청각)를 제공합니다. 마찬가지로, 만져볼 수 있는 물건들은 촉감을 통한 정보 제공에 도움을 줍니다. 멀티모달은 사람들이 정보를 더 잘 이해하고 기억하는데 도움이 될 수 있으며, 다양한 감각 채널을 통해 전달되기 때문입니다."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m멀티모달\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"멀티모달\"}):\n",
    "    print(s.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"ChatGPT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
    "\n",
    "chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "\n",
      "ChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.\n",
      "멀티모달은 여러 모드를 통해 정보를 전달하는 것을 말합니다. 이는 시각, 청각 또는 촉각을 포함할 수 있습니다. 예를 들어, 비디오는 시청자에게 동시에 이미지(시각)와 소리(청각)를 제공합니다. 마찬가지로, 만져볼 수 있는 물건들은 촉감을 통한 정보 제공에 도움을 줍니다. 멀티모달은 사람들이 정보를 더 잘 이해하고 기억하는데 도움이 될 수 있으며, 다양한 감각 채널을 통해 전달되기 때문입니다.\n",
      "프로그래밍은 복잡한 작업을 수행하기 위해 기계를 지시하는 일련의 명령어들을 작성하는 과정입니다. 이러한 명령어들은 특정 언어, 예를 들어 C++ 또는 Python을 사용하여 작성됩니다. 이 과정은 문제 해결 능력 및 논리적 사고 능력을 향상시키는 데 도움이 됩니다.\n",
      "\n",
      "1. \"머신러닝은 기계가 데이터로부터 학습하고, 패턴을 인식하고, 예측을 할 수 있게 하는 인공지능의 한 분야입니다.\"\n",
      "2. \"기계들은 인간의 개입 없이도 새로운 정보를 지속적으로 수집함으로써 지능적으로 적응할 수 있습니다.\"\n",
      "3. \"머신러닝 알고리즘과 기술은 다양한 산업 분야에서 의사결정 과정을 개선하고 효율성을 높이는 데 사용되고 있습니다.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\nChatGPT는 OpenAI에서 개발한 대화형 언어 모델로, 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계되었습니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.\\n\\nChatGPT는 대규모의 훈련 데이터와 자연어 처리 기술을 활용하여 인간과 같은 방식으로 상호작용하고 응답할 수 있도록 설계된 대화형 언어 모델입니다. 이 AI 기반 시스템은 다양한 주제에 대해 정보를 제공하고, 질문에 답하며, 대화를 나눌 수 있어 교육, 고객 지원 및 기타 여러 분야에서 유용하게 활용되고 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.',\n",
       " '\\n멀티모달은 여러 모드를 통해 정보를 전달하는 것을 말합니다. 이는 시각, 청각 또는 촉각을 포함할 수 있습니다. 예를 들어, 비디오는 시청자에게 동시에 이미지(시각)와 소리(청각)를 제공합니다. 마찬가지로, 만져볼 수 있는 물건들은 촉감을 통한 정보 제공에 도움을 줍니다. 멀티모달은 사람들이 정보를 더 잘 이해하고 기억하는데 도움이 될 수 있으며, 다양한 감각 채널을 통해 전달되기 때문입니다.',\n",
       " '\\n프로그래밍은 복잡한 작업을 수행하기 위해 기계를 지시하는 일련의 명령어들을 작성하는 과정입니다. 이러한 명령어들은 특정 언어, 예를 들어 C++ 또는 Python을 사용하여 작성됩니다. 이 과정은 문제 해결 능력 및 논리적 사고 능력을 향상시키는 데 도움이 됩니다.',\n",
       " '\\n\\n1. \"머신러닝은 기계가 데이터로부터 학습하고, 패턴을 인식하고, 예측을 할 수 있게 하는 인공지능의 한 분야입니다.\"\\n2. \"기계들은 인간의 개입 없이도 새로운 정보를 지속적으로 수집함으로써 지능적으로 적응할 수 있습니다.\"\\n3. \"머신러닝 알고리즘과 기술은 다양한 산업 분야에서 의사결정 과정을 개선하고 효율성을 높이는 데 사용되고 있습니다.\"']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최대 3개의 작업을 동시에 처리\n",
    "\n",
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비동기 for 루프(async for)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, print 함수를 통해 메시지의 내용(s.content)을 즉시 출력합니다. end=\"\"는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True는 출력 버퍼를 강제로 비워 즉시 출력되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYouTube\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s\u001b[38;5;241m.\u001b[39mcontent, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
    "async for s in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain 객체의 ainvoke 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. NonVisual Desktop Access, 즉 NVDA는 시각 장애가 있는 개인들이 화면 내용을 읽고 이해할 수 있도록 도와주는 무료 소프트웨어 응용 프로그램입니다.\n",
      "2. 이 접근성 도구로 사용자들은 키보드 단축키와 음성 합성을 통해 웹사이트, 문서 및 기타 디지털 콘텐츠를 효과적으로 상호 작용할 수 있습니다.\n",
      "3. NVDA는 다양한 운영 체제에서 사용할 수 있으며 지속적으로 업데이트되고 개선되어 시각 장애가 있는 개인들이 정보에 접근하고 기술을 활용할 수 있도록 보장합니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. NonVisual Desktop Access, 즉 NVDA는 시각 장애가 있는 개인들이 화면 내용을 읽고 이해할 수 있도록 도와주는 무료 소프트웨어 응용 프로그램입니다.\\n2. 이 접근성 도구로 사용자들은 키보드 단축키와 음성 합성을 통해 웹사이트, 문서 및 기타 디지털 콘텐츠를 효과적으로 상호 작용할 수 있습니다.\\n3. NVDA는 다양한 운영 체제에서 사용할 수 있으며 지속적으로 업데이트되고 개선되어 시각 장애가 있는 개인들이 정보에 접근하고 기술을 활용할 수 있도록 보장합니다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\n",
    "await chain.ainvoke({\"topic\": \"NVDA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다.\n",
      "인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.\n",
      "Facebook은 전 세계 수백만 명의 사람들이 친구, 가족 및 관심사와 연결될 수 있는 소셜 네트워킹 플랫폼입니다. 사용자들은 자신의 프로필을 만들고 업데이트를 게시하며 다른 사람들과 상호 작용할 수 있습니다. 또한 페이스북 메신저와 인스타그램과 같은 다양한 기능을 제공하여 사용자가 서로 소통하고 콘텐츠를 공유할 수 있게 합니다.\n",
      "\n",
      "Facebook은 2004년 하버드 대학교 학생인 마크 주커버그에 의해 창립되었습니다. 처음에는 학교 내의 학생들만을 대상으로 했지만, 이후 전 세계 수백만 명의 사용자를 보유한 글로벌 플랫폼으로 성장했습니다. Facebook은 사용자 데이터를 수집하고 이를 기반으로 타겟 광고를 제공하는 것으로 알려져 있으며, 이는 회사의 주요 수익원입니다.\n",
      "\n",
      "Facebook은 개인정보 보호 문제와 잘못된 정보 확산에 대한 비판을 받아왔으며, 이로 인해 많은 논란이 일고 있습니다. 그럼에도 불구하고 전 세계적으로 가장 인기 있는 소셜 미디어 플랫폼 중 하나로 남아있으며, 사람들이 연결되고 정보를 공유하는 데 있어 중요한 역할을 하고 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nYouTube는 사용자가 비디오를 업로드하고, 시청하며, 공유할 수 있는 인기있는 온라인 동영상 플랫폼입니다. 다양한 콘텐츠 범위가 있으며, 교육적인 것부터 오락적인 것에 이르기까지 다양합니다. 사용자는 자신의 채널을 만들고 구독자를 모으며 수익을 창출할 수도 있습니다.',\n",
       " '\\n인스타그램은 사진 및 비디오 공유를 위한 소셜 미디어 플랫폼으로, 사용자들이 자신의 경험을 친구들과 팔로워들과 공유할 수 있게 해줍니다. 인스타그램의 주요 기능으로는 필터 적용, 위치 태깅, 해시태그가 있습니다. 또한 사용자가 다른 사용자의 콘텐츠와 상호 작용할 수 있도록 좋아요 버튼과 댓글 기능을 제공합니다.',\n",
       " '\\nFacebook은 전 세계 수백만 명의 사람들이 친구, 가족 및 관심사와 연결될 수 있는 소셜 네트워킹 플랫폼입니다. 사용자들은 자신의 프로필을 만들고 업데이트를 게시하며 다른 사람들과 상호 작용할 수 있습니다. 또한 페이스북 메신저와 인스타그램과 같은 다양한 기능을 제공하여 사용자가 서로 소통하고 콘텐츠를 공유할 수 있게 합니다.\\n\\nFacebook은 2004년 하버드 대학교 학생인 마크 주커버그에 의해 창립되었습니다. 처음에는 학교 내의 학생들만을 대상으로 했지만, 이후 전 세계 수백만 명의 사용자를 보유한 글로벌 플랫폼으로 성장했습니다. Facebook은 사용자 데이터를 수집하고 이를 기반으로 타겟 광고를 제공하는 것으로 알려져 있으며, 이는 회사의 주요 수익원입니다.\\n\\nFacebook은 개인정보 보호 문제와 잘못된 정보 확산에 대한 비판을 받아왔으며, 이로 인해 많은 논란이 일고 있습니다. 그럼에도 불구하고 전 세계적으로 가장 인기 있는 소셜 미디어 플랫폼 중 하나로 남아있으며, 사람들이 연결되고 정보를 공유하는 데 있어 중요한 역할을 하고 있습니다.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\n",
    "await chain.abatch(\n",
    "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language(LCEL)\n",
    "\n",
    "https://wikidocs.net/233344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "영어 대화 예시:\n",
      "\n",
      "English Conversation:\n",
      "I would like to order some food at the restaurant, please.\n",
      "Can I have a menu?\n",
      "Sure, here you go. Please take your time and look through it. If you need any help or recommendations, just let me know.\n",
      "Thank you very much! I'll take a moment to decide what I want.\n",
      "Great, we appreciate your business. Let us know when you're ready to place your order.\n",
      "I think I found something that looks good. Can I have the [specific dish] please?\n",
      "Sure thing! Would you like anything else with it or any side dishes?\n",
      "No thank you, just the main dish is fine for now.\n",
      "Alright then, we will get right on that and bring it out to your table shortly. Enjoy your meal!\n",
      "영어 대화 예시:\n",
      "\n",
      "English Conversation:\n",
      "I would like to order some food at the restaurant, please.\n",
      "Can I have a menu?\n",
      "Sure, here you go. Please take your time and look through it. If you need any help or recommendations, just let me know.\n",
      "Thank you very much! I'll take a moment to decide what I want.\n",
      "Great, we appreciate your business. Let us know when you're ready to place your order.\n",
      "I think I found something that looks good. Can I have the [specific dish] please?\n",
      "Sure thing! Would you like anything else with it or any side dishes?\n",
      "No thank you, just the main dish is fine for now.\n",
      "Alright then, we will get right on that and bring it out to your table shortly. Enjoy your meal!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "\n",
    "# 2\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 3\n",
    "template = \"\"\"\n",
    "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
    "답변은 항상 한글로 작성해 주세요.\n",
    "\n",
    "질문:\n",
    "{question}에 대하여 설명해 주세요.\n",
    "\n",
    "FORMAT:\n",
    "- 개요:\n",
    "- 예시:\n",
    "- 출처:\n",
    "\"\"\"\n",
    "\n",
    "# 4\n",
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "##########\n",
    "# llm 모델\n",
    "##########\n",
    "local_path = (\n",
    "    \"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\"\n",
    ")\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    backend=\"mps\", # GPU 설정\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSONPatch 청크 스트리밍\n",
    "\n",
    "https://wikidocs.net/233345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta. Creating a new one with MEAN pooling.\n",
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/langchain/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '65842086-4c8f-4148-9f4c-0d58101b8f59',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'ecfbd609-acec-4293-80ea-609f46f99ad9',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2024-05-14T13:39:57.127+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:context', 'FAISS', 'HuggingFaceBgeEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='원영이가 살고 있는 곳은 대한민국 입니다.')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2024-05-14T13:39:57.248+00:00'})\n",
      "\n",
      "A. 미국\n",
      "B. 중국\n",
      "C. 일본\n",
      "D. 대한민국\n",
      "\n",
      "정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. 따라서 정답은 D 옵션인 '대한민국'입니다.----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': '\\n'\n",
      "           'A. 미국\\n'\n",
      "           'B. 중국\\n'\n",
      "           'C. 일본\\n'\n",
      "           'D. 대한민국\\n'\n",
      "           '\\n'\n",
      "           '정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. '\n",
      "           \"따라서 정답은 D 옵션인 '대한민국'입니다.\"},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': '\\n'\n",
      "           'A. 미국\\n'\n",
      "           'B. 중국\\n'\n",
      "           'C. 일본\\n'\n",
      "           'D. 대한민국\\n'\n",
      "           '\\n'\n",
      "           '정답은 D입니다. 제공된 문맥에 따르면, \"원영이는 대한민국에 거주하고 있습니다.\"라고 명시되어 있기 때문입니다. '\n",
      "           \"따라서 정답은 D 옵션인 '대한민국'입니다.\"})\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "##########\n",
    "# llm 모델\n",
    "##########\n",
    "local_path = (\n",
    "    \"./EEVE-Korean-Instruct-10.8B-v1.0-gguf/EEVE-Korean-Instruct-10.8B-v1.0-Q5_K_M.gguf\"\n",
    ")\n",
    "llm = GPT4All(\n",
    "    model=local_path,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    backend=\"mps\", # GPU 설정\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "#################\n",
    "# embedding model\n",
    "#################\n",
    "model_name = 'BM-K/KoSimCSE-roberta'\n",
    "model_kwargs = {'device': 'mps'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "###################################\n",
    "#  FAISS 벡터 스토어를 이용해 텍스트를 인덱싱\n",
    "###################################\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"원영이가 살고 있는 곳은 대한민국 입니다.\"], embedding=embeddings_model\n",
    ")\n",
    "#########################################################################\n",
    "# retriever와 RunnablePassthrough를 통해 질문의 컨텍스트를 검색하고, 질문을 그대로 전달\n",
    "# retrieval_chain은 이러한 컴포넌트들을 파이프라인으로 연결하고, StrOutputParser를 사용하여 모델의 출력을 문자열로 파싱합니다.\n",
    "#########################################################################\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# astream_log: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다\n",
    "async for chunk in retrieval_chain.astream_log(\n",
    "    \"원영이가 살고 있는 곳은 어딘가요?\", include_names=[\"Docs\"]\n",
    "):\n",
    "    print(\"-\" * 40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1256bc89-d924-4cef-99e4-6060f52f153a',\n",
      " 'logs': {},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1256bc89-d924-4cef-99e4-6060f52f153a',\n",
      " 'logs': {'Docs': {'end_time': None,\n",
      "                   'final_output': None,\n",
      "                   'id': 'ba928e32-0711-47d7-b160-d48ca6c56e32',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-05-14T13:40:09.790+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context',\n",
      "                            'FAISS',\n",
      "                            'HuggingFaceBgeEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "----------------------------------------------------------------------\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1256bc89-d924-4cef-99e4-6060f52f153a',\n",
      " 'logs': {'Docs': {'end_time': '2024-05-14T13:40:09.915+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content='원영이가 살고 있는 곳은 대한민국 입니다.')]},\n",
      "                   'id': 'ba928e32-0711-47d7-b160-d48ca6c56e32',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-05-14T13:40:09.790+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context',\n",
      "                            'FAISS',\n",
      "                            'HuggingFaceBgeEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': [],\n",
      " 'type': 'chain'})\n",
      "\n",
      "A: 대한민국에 삽니다.----------------------------------------------------------------------\n",
      "RunLog({'final_output': '\\nA: 대한민국에 삽니다.',\n",
      " 'id': '1256bc89-d924-4cef-99e4-6060f52f153a',\n",
      " 'logs': {'Docs': {'end_time': '2024-05-14T13:40:09.915+00:00',\n",
      "                   'final_output': {'documents': [Document(page_content='원영이가 살고 있는 곳은 대한민국 입니다.')]},\n",
      "                   'id': 'ba928e32-0711-47d7-b160-d48ca6c56e32',\n",
      "                   'metadata': {},\n",
      "                   'name': 'Docs',\n",
      "                   'start_time': '2024-05-14T13:40:09.790+00:00',\n",
      "                   'streamed_output': [],\n",
      "                   'streamed_output_str': [],\n",
      "                   'tags': ['map:key:context',\n",
      "                            'FAISS',\n",
      "                            'HuggingFaceBgeEmbeddings'],\n",
      "                   'type': 'retriever'}},\n",
      " 'name': 'RunnableSequence',\n",
      " 'streamed_output': ['\\nA: 대한민국에 삽니다.'],\n",
      " 'type': 'chain'})\n"
     ]
    }
   ],
   "source": [
    "# retrieval_chain 객체의 astream_log 비동기 메서드를 사용하여 로그 데이터를 비동기적으로 검색\n",
    "# \"Docs\"를 포함한 로그만을 필터링합니다. diff 매개변수는 False로 설정되어 있어, 변경 사항에 대한 차이점을 표시하지 않습니다. \n",
    "# 각 로그 청크(chunk)가 검색될 때마다, 청크의 내용을 출력하기 전에 구분선을 출력합니다\n",
    "\n",
    "async for chunk in retrieval_chain.astream_log(\n",
    "    \"원영가 살고 있는 곳은 어딘가요?\", include_names=[\"Docs\"], diff=False\n",
    "):\n",
    "    print(\"-\" * 70)\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
    "chain1 = ChatPromptTemplate.from_template(\"{country} 의 수도는 어디야?\") | llm\n",
    "\n",
    "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
    "chain2 = ChatPromptTemplate.from_template(\"{country} 의 면적은 얼마야?\") | llm\n",
    "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
    "combined = RunnableParallel(capital=chain1, area=chain2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답변: 서울입니다.\n",
      "신뢰도: 95%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n답변: 서울입니다.\\n신뢰도: 95%'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "대한민국의 총면적이 몇 제곱킬로미터인지 알고 싶어요."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n대한민국의 총면적이 몇 제곱킬로미터인지 알고 싶어요.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답변: 서울입니다.\n",
      "신뢰도: 95%\n",
      "신뢰도: 95%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n답변: 서울입니다.\\n신뢰도: 95%', '\\n신뢰도: 95%']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "대한민국의 총면적이 몇 제곱킬로미터인지 알고 싶어요.\n",
      "미국 대륙의 총 면적을 말씀하시는 건가요, 아니면 미국의 영토를 말하는 건지요? 만약 후자라면 983만 제곱킬로미터(약 379만 평방마일)입니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n대한민국의 총면적이 몇 제곱킬로미터인지 알고 싶어요.',\n",
       " '\\n미국 대륙의 총 면적을 말씀하시는 건가요, 아니면 미국의 영토를 말하는 건지요? 만약 후자라면 983만 제곱킬로미터(약 379만 평방마일)입니다.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 주어진 'country'에 대해 'combined' 객체의 'invoke' 메서드를 호출합니다.\n",
    "combined.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 주어진 데이터를 배치로 처리합니다.\n",
    "combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
